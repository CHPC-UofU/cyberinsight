# CyberInsight Tool Evaluation and Comparison with NAG's HPC TCO Tool

Author: Paul Fischer (CHPC)  
Last updated: 2020-01-22

CyberInsight: https://tco.sites.uiowa.edu/about-cyber-insight  
NSF Award #1812786: https://www.nsf.gov/awardsearch/showAward?AWD_ID=1812786

Numerical Algorithms Group (NAG), HPC TCO tool: https://www.nag.com/content/hpc-tco-calculator

## Summary

This is a brief evaluation of the CyberInsight project tool in the context of the Numerical Algorithms Group's analogous tool. In general, the NAG tool offers a significantly better user experience over the CyberInsight (CI) model due to multiple factors outlined below. However, the CI tool has some notable feature advantages for a technical audience.

These advantages are not mutually exclusive and a new, more usable tool (notebook or webpage) could be developed that incorporates the positive features from both tools. However, this would take around a month of development time to produce a sustainable product building off the work done on both tools.

### Recommended areas of improvement for CyberInsight  
* _Streamline interface_
    * 1 notebook with data entry functionality through `ipywidgets`
    * Remove spreadsheet, server (database + notebook hosting) and any other local system requirements
* _Increase model transparency_
    * Require only primary data from users to minimize ambiguity of derived metrics
        * See personnel cost comparison in **Model design** section below
    * Describe the model with embedded $\LaTeX$ or otherwise.
    * Clean up & document the backend TCO Python library.
    * Simplify visualization code with Plotly instead of Matplotlib.
    
***

## Comparisons

### Tool architecture at a glance
**CI:**
* 1x local Excel Spreadsheet (.xlsx)
* 2x hosted/local Jupyter notebooks (.ipynb)
* 1x Server provisioned for JupyterHub and MySQL
* 6x backend CSV files (.csv)

**NAG:**
* 1x hosted web form in basic HTML + minimal JS (.html via web browser)

### Tool features & drawbacks

**CI:**
* [+] Model/tool transparency
    * Python source code immediately available
    * Source code is modestly organized but poorly documented
* [+] Data persistence and export 
    * Data+results saved to CSV
* [+] Generated bar, line chart visualizations
* [+] Data granularity
    * Per-benchmark comparisons
    * Storage costs included
* [-] 16 usage steps described, key highlights:
    * Locally edit a raw spreadsheet
    * Download and upload files in Jupyter
    * Run Jupyter notebook cells
    * Interact with a disparate UI generated by multiple cells
* [-] No troubleshooting assistance
    * Jupyter notebook errors
    * Data entry errors
* [-] Implicit data-crunching required of users
    * To calculate e.g. personnel, power costs
    * Introduces validity errors

**NAG:**
* [+] Self-explanatory web form data entry
    * TCO results populate automatically
    * A 6-minute video tutorial is linked
* [+] Immediately accessible from any web browser
    * https://www.nag.com/content/hpc-tco-calculator
* [+] Streamlined parameters require minimal calculation from user
* [-] No data persistence/export feature 
* [-] Opaque model
    * Associated spreadsheet is available upon request

### Model design

#### Personnel cost parameters
**CI:**
* "Personnel Setup Cost" (\$)
* "Monthly Personnel Cost" (\$/month)

**NAG:**
* "Cost per FTE per year" (\$/year)
* "Effort spent on procurement & commissioning" (person-years)
* "Effort spent on decommissioning" (person-years)
* "System management team size" (persons)
* "User support team size" (persons)

***

## Appendix



### Appendix A: CyberInsight Parameters and Results
27-35 data inputs. Data is entered into a local Excel Spreadsheet. 

#### System Information
* Organization Name
* System Name (i.e. Resource/Cluster name)
* System Description
* System Type [OnPrem/Cloud]
* Deployment Date

#### Benchmark Information
* Measurement Name (i.e. Benchmark name)
* X Unit Name (e.g. # of nodes)
* Y Unit Name (e.g. Rmax-TFLOPS)
* Benchmark Date

#### Benchmark Data
* 5 X/Y pairs for 5 results

#### TCO Data for On-Premise
* Node Count
* Cost per Node
* Rack Infrastructure Cost
* Power Infrastructure Cost
* MONTHLY Data Center Cost
* MONTHLY Expected Power
* Power Cost per kW/h
* Personnel Setup Cost
* MONTHLY Personnel Cost

#### TCO Data for Cloud
* Instance Count
* HOURLY Instance Cost
* Storage Requirement
* MONTHLY Storage Cost per GB
* MONTHLY Expected Network Transfer Cost
* Personnel Setup Cost
* MONTHLY Personnel Cost

#### [Result] Chart visualizations
* Bar chart: TCO aggregate with breakdown
    * Personnel
    * Server
    * Storage
    * Network
    * Rack Infrastructure
    * Power Infrastructure
    * Power Consumption
    * Cloud Instances
    
* Line chart: TCO projections

***

### Appendix B: NAG HPC TCO Parameters and Results
22 data inputs. Data is entered into a dynamic web form.

#### Baseline TCO Model for On-Premises HPC Service
* Cost of electricity ($ per kW/h)
* PUE (DC power / Subset delivered to compute)
* Capital (up-front hardware costs)
* {calculated} Number of racks
* Power consumption (kW/rack)
* Utilization (utilized cycles \%)
* Service time (usable uptime \%)
* {calculated} Total number of core-hrs UTILIZED per year
* Cost of a person per year
* Price per node
* Nodes per rack
* {calculated} Price per rack
* Cores per node
* Cost of hosting per rack per year (DC cost)
* Effort spent on procurement & commissioning (person years)
* Effort spent on decommissioning (person years)
* System management team size
* User support team size
* Per-year occupancy \%s (5 year model; <1 for first and last year)

#### [Result] On-Premises Key Metrics
* TCO
* Actual cost per core-hour UTILIZED

#### TCO Model for Cloud Computing to deliver same amount of actual used core-hours
* Cost of cloud cycles - $ per core-hour
* {calculated} Total number of core-hours used per year
* Cost of a person per year
* Effort spent on procurement & commissioning (person years)
* Effort spent on decommissioning (person years)
* Cloud management/support team size
* User support team size

#### [Result] Comparison Metrics
* On-prem TCO
* Cloud TCO
* Cloud - actual cost per core-hour UTILIZED
* Cloud/OnPrem TCO ratio

***
